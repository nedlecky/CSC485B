{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nedlecky/CSC485B/blob/main/CSC485_140_PythagorasPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSC 485B Spring 2023: CSC485_140_PythagorasPipeline using MLP\n",
        "## Using the Pythagoras problem to illustrate pipelines\n",
        "### Input the length of the two sides, ML computes hypotenuse, perimeter, and area\n",
        "* SUNY Plattsburgh, Spring 2023\n",
        "* Dr. Ned Lecky\n",
        "* nleck001@plattsburgh.edu\n",
        "* ned@lecky.com"
      ],
      "metadata": {
        "id": "QBwjvn9X7lgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our output directories\n",
        "from pathlib import Path\n",
        "\n",
        "OUTPUT_PATH = Path() / \"pipeline\"\n",
        "IMAGES_PATH = Path() / OUTPUT_PATH / \"images\""
      ],
      "metadata": {
        "id": "FlSDOXFHCmYc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Support Functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "# This makes us reproducible (and we can adjust fixed_seed to get different results)\n",
        "fixed_seed = 1\n",
        "\n",
        "# Return n random floats between lo and hi as 1-column NumPy matrix\n",
        "def rand_nlohi(n=1, lo=0, hi=1):\n",
        "  # This is just a uniform distribution from lo to hi... we can adjust if appropriate in the future\n",
        "  return (np.random.rand(n) * (hi - lo) + lo).reshape(-1,1)\n",
        "\n",
        "# Often a good idea as long as we are keeping values near +/- 1... don't need exponential notation\n",
        "np.set_printoptions(floatmode='fixed', precision=4, suppress=True)\n",
        "# This will get us all 400 rows printed... which fails past 40 x 2 columns\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "# Simple numpy array print with optional push to file\n",
        "def nprint(m, name='', also_write_file=False):\n",
        "  print(f\"{name} {m.shape} {m.dtype}\")\n",
        "  print(m)\n",
        "  if also_write_file and name != '':\n",
        "    fprint(m, name)\n",
        "\n",
        "# Print numpy array to file (needs name)\n",
        "def fprint(m, name='', path=OUTPUT_PATH):\n",
        "  if name != '':\n",
        "    with open(path /  name, 'w') as f:\n",
        "      print(f\"{name} {m.shape} {m.dtype}\", file=f)\n",
        "      print(m, file=f)\n",
        "  else:\n",
        "    print('fprint needs a name!')\n",
        "\n",
        "# Remove a file and don't complain if it doesn't exist\n",
        "def remove_file(name):\n",
        "  try:\n",
        "    os.remove(name)\n",
        "  except:\n",
        "    return\n",
        "\n",
        "# Delete a directory, recursively removing files and subdirectories\n",
        "def delete_directory(path):\n",
        "  if not OUTPUT_PATH.exists():\n",
        "    return\n",
        "\n",
        "  print(f\"delete_directory({path})\")\n",
        "  for file_name in os.listdir(path):\n",
        "    # construct full file path\n",
        "    file = path / file_name\n",
        "    if os.path.isdir(file):\n",
        "        print('  found subdirectory', file)\n",
        "        delete_directory(file)\n",
        "    elif os.path.isfile(file):\n",
        "        print('  deleting file', file)\n",
        "        os.remove(file)\n",
        "  os.rmdir(path)\n",
        "\n",
        "# Save a matplotlib figure to a png file\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "# Makes default plots a bit cleaner\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)\n",
        "\n",
        "# Compare a Y with a Y_pred\n",
        "def compare_results(Y, Y_pred):\n",
        "  print(f\"Mean squared error: {mean_squared_error(Y, Y_pred):.2f}\")\n",
        "  print(f\"Mean absolute error: {mean_absolute_error(Y, Y_pred):.2f}\")\n",
        "  print(f\"Mean absolute percentage error: {mean_absolute_percentage_error(Y, Y_pred):.2f}\")\n",
        "\n",
        "  # Add the Pandas describe()\n",
        "  df = pd.DataFrame(data = Y_pred - Y)\n",
        "  print(df.describe())\n"
      ],
      "metadata": {
        "id": "0B_bKL2AjY7z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup (and clear) output directories\n",
        "delete_directory(OUTPUT_PATH)\n",
        "\n",
        "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fteMAJjMCwlv",
        "outputId": "07c9fe42-de6f-4894-cc1f-6a37159b5069"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delete_directory(pipeline)\n",
            "  deleting file pipeline/X_train\n",
            "  deleting file pipeline/Y_test\n",
            "  deleting file pipeline/Y_test_pred1\n",
            "  deleting file pipeline/Y_pred1\n",
            "  deleting file pipeline/X\n",
            "  deleting file pipeline/X_test\n",
            "  deleting file pipeline/Y_train_pred1\n",
            "  deleting file pipeline/XY\n",
            "  deleting file pipeline/Y_train\n",
            "  deleting file pipeline/X_raw\n",
            "  deleting file pipeline/Y:Y_pred2\n",
            "  deleting file pipeline/Y:Y_pred1\n",
            "  deleting file pipeline/Y\n",
            "  found subdirectory pipeline/images\n",
            "delete_directory(pipeline/images)\n",
            "  deleting file pipeline/X:X_scaled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Test Data\n",
        "\n"
      ],
      "metadata": {
        "id": "YL7kMtd55FpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X is triangles with side1 side2 spread from 2 to 2000 cm"
      ],
      "metadata": {
        "id": "IROru1MoDTLw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nedp4wU8pITb"
      },
      "outputs": [],
      "source": [
        "# This is the full test input data for right triangles\n",
        "# Reminder: Final input is the length of the two sides, output is length of hypotenuse, perimeter, and area\n",
        "# x = [side1, side2]\n",
        "# y = [hypotenuse, perimeter, area]\n",
        "\n",
        "np.random.seed(fixed_seed)\n",
        "\n",
        "# Setup what you want to generate\n",
        "N = 1000\n",
        "shortest_side = 2\n",
        "longest_side = 2000\n",
        "raw_scale = np.array([0.01, 0.01])\n",
        "\n",
        "# Generate X\n",
        "side1 = rand_nlohi(N, shortest_side, longest_side)\n",
        "side2 = rand_nlohi(N, shortest_side, longest_side)\n",
        "\n",
        "X_raw = np.hstack([side1, side2])\n",
        "fprint(X_raw,'X_raw')\n",
        "X = X_raw * raw_scale\n",
        "\n",
        "fprint(X,'X')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y can be computed from X"
      ],
      "metadata": {
        "id": "-hwvKXRZRQ1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's compute the FULL Y expected results\n",
        "# Reminder: We tell you the length of the two sides, you compute length of hypotenuse, perimeter, and area\n",
        "# x = [side1, side2]\n",
        "# y = [hypotenuse, perimeter, area]\n",
        "\n",
        "hypotenuse = np.sqrt(np.square(X[:,0:1]) + np.square(X[:,1:2]))\n",
        "perimeter = X[:,0:1] + X[:,1:2] + hypotenuse\n",
        "area = (X[:,0:1] * X[:,1:2]) / 2.\n",
        "Y = np.hstack([hypotenuse, perimeter, area])\n",
        "fprint(Y,'Y')\n",
        "fprint(np.hstack([X,Y]), 'XY')\n",
        "\n",
        "# Optional noise in Y\n",
        "# Not tested yet!\n",
        "# Just bump all up or down by up to 1%\n",
        "#Y = Y * (100. + (np.random.rand(Y.shape[0],Y.shape[1])-0.5))/100.\n"
      ],
      "metadata": {
        "id": "w0drnB6qkR9v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split, Scale, Train, Test"
      ],
      "metadata": {
        "id": "AP9m5U--Q8_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without Pipeline"
      ],
      "metadata": {
        "id": "ma8jndL2Pw-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# Split\n",
        "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
        "fprint(X_train, 'X_train')\n",
        "fprint(X_test, 'X_test')\n",
        "fprint(Y_train, 'Y_train')\n",
        "fprint(Y_test, 'Y_test')\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_scaled = scaler.transform(X)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "fprint(np.hstack([X, X_scaled]),'X:X_scaled')\n",
        "\n",
        "# Train\n",
        "mlp = MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
        "          hidden_layer_sizes=(20,20),\n",
        "          activation='relu',\n",
        "          max_iter=10000,\n",
        "          random_state=1,\n",
        "          verbose=True)\n",
        "mlp.fit(X_train_scaled, Y_train)\n",
        "\n",
        "# Test\n",
        "Y_test_pred1 = mlp.predict(scaler.transform(X_test)).reshape(Y_test.shape[0],-1)\n",
        "Y_train_pred1 = mlp.predict(scaler.transform(X_train)).reshape(Y_train.shape[0],-1)\n",
        "Y_pred1 = mlp.predict(scaler.transform(X)).reshape(Y.shape[0],-1)\n",
        "fprint(Y_test_pred1,'Y_test_pred1')\n",
        "fprint(Y_train_pred1,'Y_train_pred1')\n",
        "fprint(Y_pred1,'Y_pred1')\n",
        "\n",
        "fprint(np.hstack([Y, Y_pred1]),'Y:Y_pred1')\n",
        "\n",
        "compare_results(Y_test, Y_test_pred1)\n",
        "compare_results(Y_train, Y_train_pred1)\n",
        "compare_results(Y, Y_pred1)"
      ],
      "metadata": {
        "id": "-gfjC9sRQ9qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929a93c8-6fd1-4b2c-dc66-9f4572e5a6ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 0.05\n",
            "Mean absolute error: 0.14\n",
            "Mean absolute percentage error: 0.03\n",
            "                0           1           2\n",
            "count  300.000000  300.000000  300.000000\n",
            "mean    -0.003450   -0.002841    0.022104\n",
            "std      0.102420    0.103762    0.338390\n",
            "min     -0.304946   -0.301717   -1.026736\n",
            "25%     -0.060992   -0.060091   -0.185651\n",
            "50%      0.006714    0.006038   -0.005809\n",
            "75%      0.058255    0.060986    0.204326\n",
            "max      0.309296    0.312034    0.963792\n",
            "Mean squared error: 0.03\n",
            "Mean absolute error: 0.12\n",
            "Mean absolute percentage error: 0.01\n",
            "                0           1           2\n",
            "count  700.000000  700.000000  700.000000\n",
            "mean    -0.000145   -0.000025    0.000199\n",
            "std      0.087893    0.088099    0.275008\n",
            "min     -0.309017   -0.305330   -0.747611\n",
            "25%     -0.047334   -0.046788   -0.191338\n",
            "50%      0.007440    0.005454   -0.012277\n",
            "75%      0.055687    0.057641    0.156301\n",
            "max      0.234268    0.231949    1.434314\n",
            "Mean squared error: 0.03\n",
            "Mean absolute error: 0.12\n",
            "Mean absolute percentage error: 0.01\n",
            "                 0            1            2\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     -0.001137    -0.000870     0.006771\n",
            "std       0.092451     0.093031     0.295450\n",
            "min      -0.309017    -0.305330    -1.026736\n",
            "25%      -0.053702    -0.052392    -0.190269\n",
            "50%       0.007134     0.005454    -0.006586\n",
            "75%       0.056538     0.058383     0.176567\n",
            "max       0.309296     0.312034     1.434314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Pipeline"
      ],
      "metadata": {
        "id": "hyt4Q6xIP0pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('MLP', MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
        "          hidden_layer_sizes=(20,20),\n",
        "          activation='relu',\n",
        "          max_iter=10000,\n",
        "          random_state=1,\n",
        "          verbose=True))\n",
        "    ])\n",
        "pipe.fit(X_train, Y_train)\n",
        "print(f\"pipe.score = {100*pipe.score(X_test, Y_test):.4f}%\")\n",
        "Y_pred2 = pipe.predict(X)\n",
        "Y_test_pred2 = pipe.predict(X_test)\n",
        "Y_train_pred2 = pipe.predict(X_train)\n",
        "\n",
        "fprint(np.hstack([Y, Y_pred2]),'Y:Y_pred2')\n",
        "\n",
        "compare_results(Y_test, Y_test_pred2)\n",
        "compare_results(Y_train, Y_train_pred2)\n",
        "compare_results(Y, Y_pred2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BbUPp8oFR9J",
        "outputId": "8b3e42f5-6e89-4e6e-b6c9-db4665486f53"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipe.score = 99.9909%\n",
            "Mean squared error: 0.03\n",
            "Mean absolute error: 0.12\n",
            "Mean absolute percentage error: 0.02\n",
            "                0           1           2\n",
            "count  300.000000  300.000000  300.000000\n",
            "mean     0.004843    0.005319   -0.006210\n",
            "std      0.085009    0.088187    0.299799\n",
            "min     -0.346555   -0.339149   -0.979231\n",
            "25%     -0.036678   -0.034487   -0.174367\n",
            "50%      0.004430    0.003833   -0.026518\n",
            "75%      0.039556    0.046481    0.175358\n",
            "max      0.325738    0.430920    0.904748\n",
            "Mean squared error: 0.02\n",
            "Mean absolute error: 0.09\n",
            "Mean absolute percentage error: 0.01\n",
            "                0           1           2\n",
            "count  700.000000  700.000000  700.000000\n",
            "mean     0.000051    0.000057   -0.000253\n",
            "std      0.063795    0.063696    0.226644\n",
            "min     -0.296048   -0.320930   -0.617571\n",
            "25%     -0.033548   -0.032011   -0.148816\n",
            "50%      0.004504    0.001960    0.003413\n",
            "75%      0.031778    0.034881    0.131749\n",
            "max      0.217836    0.207927    0.958258\n",
            "Mean squared error: 0.02\n",
            "Mean absolute error: 0.10\n",
            "Mean absolute percentage error: 0.01\n",
            "                 0            1            2\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean      0.001488     0.001635    -0.002040\n",
            "std       0.070820     0.071918     0.250699\n",
            "min      -0.346555    -0.339149    -0.979231\n",
            "25%      -0.034055    -0.033486    -0.158241\n",
            "50%       0.004466     0.002289    -0.000225\n",
            "75%       0.033505     0.037223     0.140187\n",
            "max       0.325738     0.430920     0.958258\n"
          ]
        }
      ]
    }
  ]
}