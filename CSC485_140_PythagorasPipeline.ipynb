{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nedlecky/CSC485B/blob/main/CSC485_140_PythagorasPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSC 485B Spring 2023: CSC485_140_PythagorasPipeline using MLP\n",
        "## Using the Pythagoras problem to illustrate pipelines\n",
        "### Input the length of the two sides, ML computes hypotenuse, perimeter, and area\n",
        "* SUNY Plattsburgh, Spring 2023\n",
        "* Dr. Ned Lecky\n",
        "* nleck001@plattsburgh.edu\n",
        "* ned@lecky.com"
      ],
      "metadata": {
        "id": "QBwjvn9X7lgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify output directories\n",
        "from pathlib import Path\n",
        "\n",
        "OUTPUT_PATH = Path() / \"pipeline\"\n",
        "IMAGES_PATH = Path() / OUTPUT_PATH / \"images\""
      ],
      "metadata": {
        "id": "FlSDOXFHCmYc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Support Functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "# This makes us reproducible (and we can adjust fixed_seed to get different results)\n",
        "fixed_seed = 1\n",
        "\n",
        "# Return n random floats between lo and hi as 1-column NumPy matrix\n",
        "def rand_nlohi(n=1, lo=0, hi=1):\n",
        "  # This is just a uniform distribution from lo to hi... we can adjust if appropriate in the future\n",
        "  return (np.random.rand(n) * (hi - lo) + lo).reshape(-1,1)\n",
        "\n",
        "# Often a good idea as long as we are keeping values near +/- 1... don't need exponential notation\n",
        "np.set_printoptions(floatmode='fixed', precision=4, suppress=True)\n",
        "# This will get us all 400 rows printed... which fails past 40 x 2 columns\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "# Simple numpy array print with optional push to file\n",
        "def nprint(m, name='', also_write_file=False):\n",
        "  print(f\"{name} {m.shape} {m.dtype}\")\n",
        "  print(m)\n",
        "  if also_write_file and name != '':\n",
        "    fprint(m, name)\n",
        "\n",
        "# Print numpy array to file (needs name)\n",
        "def fprint(m, name='', path=OUTPUT_PATH):\n",
        "  if name != '':\n",
        "    with open(path /  name, 'w') as f:\n",
        "      print(f\"{name} {m.shape} {m.dtype}\", file=f)\n",
        "      print(m, file=f)\n",
        "  else:\n",
        "    print('fprint needs a name!')\n",
        "\n",
        "# Remove a file and don't complain if it doesn't exist\n",
        "def remove_file(name):\n",
        "  try:\n",
        "    os.remove(name)\n",
        "  except:\n",
        "    return\n",
        "\n",
        "# Delete a directory, recursively removing files and subdirectories\n",
        "def delete_directory(path):\n",
        "  if not OUTPUT_PATH.exists():\n",
        "    return\n",
        "\n",
        "  print(f\"delete_directory({path})\")\n",
        "  for file_name in os.listdir(path):\n",
        "    # construct full file path\n",
        "    file = path / file_name\n",
        "    if os.path.isdir(file):\n",
        "        print('  found subdirectory', file)\n",
        "        delete_directory(file)\n",
        "    elif os.path.isfile(file):\n",
        "        print('  deleting file', file)\n",
        "        os.remove(file)\n",
        "  os.rmdir(path)\n",
        "\n",
        "# Save a matplotlib figure to a png file\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "# Makes default plots a bit cleaner\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)\n",
        "\n",
        "# Compare a Y with a Y_pred\n",
        "def compare_results(Y, Y_pred):\n",
        "  print(f\"Mean squared error: {mean_squared_error(Y, Y_pred):.2f}\")\n",
        "  print(f\"Mean absolute error: {mean_absolute_error(Y, Y_pred):.2f}\")\n",
        "  print(f\"Mean absolute percentage error: {mean_absolute_percentage_error(Y, Y_pred):.2f}\")\n",
        "\n",
        "  # Add the Pandas describe()\n",
        "  df = pd.DataFrame(data = Y_pred - Y)\n",
        "  print(df.describe())\n"
      ],
      "metadata": {
        "id": "0B_bKL2AjY7z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup (and clear) output directories\n",
        "delete_directory(OUTPUT_PATH)\n",
        "\n",
        "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "fteMAJjMCwlv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Test Data\n",
        "\n"
      ],
      "metadata": {
        "id": "YL7kMtd55FpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X is triangles with side1 side2 spread from 2 to 2000 cm"
      ],
      "metadata": {
        "id": "IROru1MoDTLw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nedp4wU8pITb"
      },
      "outputs": [],
      "source": [
        "# This is the full test input data for right triangles\n",
        "# Reminder: Final input is the length of the two sides, output is length of hypotenuse, perimeter, and area\n",
        "# x = [side1, side2]\n",
        "# y = [hypotenuse, perimeter, area]\n",
        "\n",
        "np.random.seed(fixed_seed)\n",
        "\n",
        "# Setup what you want to generate\n",
        "N = 400\n",
        "shortest_side = 2\n",
        "longest_side = 2000\n",
        "raw_scale = np.array([0.01, 0.01])\n",
        "\n",
        "# Generate X\n",
        "side1 = rand_nlohi(N, shortest_side, longest_side)\n",
        "side2 = rand_nlohi(N, shortest_side, longest_side)\n",
        "\n",
        "X_raw = np.hstack([side1, side2])\n",
        "fprint(X_raw,'X_raw')\n",
        "X = X_raw * raw_scale\n",
        "\n",
        "fprint(X,'X')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y can be computed from X Exactly"
      ],
      "metadata": {
        "id": "-hwvKXRZRQ1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's compute the expected Y\n",
        "# Reminder: We tell you the length of the two sides, you compute length of hypotenuse, perimeter, and area\n",
        "# x = [side1, side2]\n",
        "# y = [hypotenuse, perimeter, area]\n",
        "\n",
        "hypotenuse = np.sqrt(np.square(X[:,0:1]) + np.square(X[:,1:2]))\n",
        "perimeter = X[:,0:1] + X[:,1:2] + hypotenuse\n",
        "area = (X[:,0:1] * X[:,1:2]) / 2.\n",
        "Y_exact = np.hstack([hypotenuse, perimeter, area])\n",
        "\n",
        "# Optional noise in Y\n",
        "# Not tested yet!\n",
        "noise_pct = 1.00\n",
        "# Just bump all up or down by up to noise_pct\n",
        "Y = Y_exact * (1 + noise_pct/100. * (np.random.rand(Y_exact.shape[0], Y_exact.shape[1]) - 0.5))\n",
        "\n",
        "fprint(Y_exact,'Y_exact')\n",
        "fprint(Y,'Y')\n",
        "fprint(np.hstack([X, Y]), 'X:Y')\n",
        "fprint(np.hstack([Y_exact, Y]), 'Y_exact:Y')\n"
      ],
      "metadata": {
        "id": "w0drnB6qkR9v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split, Scale, Train, Test"
      ],
      "metadata": {
        "id": "AP9m5U--Q8_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without Pipeline"
      ],
      "metadata": {
        "id": "ma8jndL2Pw-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# Split\n",
        "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
        "fprint(X_train, 'X_train')\n",
        "fprint(X_test, 'X_test')\n",
        "fprint(Y_train, 'Y_train')\n",
        "fprint(Y_test, 'Y_test')\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_scaled = scaler.transform(X)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "fprint(np.hstack([X, X_scaled]),'X:X_scaled')\n",
        "\n",
        "# Train\n",
        "mlp = MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
        "          hidden_layer_sizes=(20,20),\n",
        "          activation='relu',\n",
        "          max_iter=10000,\n",
        "          random_state=1,\n",
        "          verbose=True)\n",
        "mlp.fit(X_train_scaled, Y_train)\n",
        "\n",
        "# Test\n",
        "Y_test_pred1 = mlp.predict(scaler.transform(X_test)).reshape(Y_test.shape[0],-1)\n",
        "Y_train_pred1 = mlp.predict(scaler.transform(X_train)).reshape(Y_train.shape[0],-1)\n",
        "Y_pred1 = mlp.predict(scaler.transform(X)).reshape(Y.shape[0],-1)\n",
        "fprint(Y_test_pred1,'Y_test_pred1')\n",
        "fprint(Y_train_pred1,'Y_train_pred1')\n",
        "fprint(Y_pred1,'Y_pred1')\n",
        "\n",
        "fprint(np.hstack([Y, Y_pred1]),'Y:Y_pred1')\n",
        "\n",
        "compare_results(Y_test, Y_test_pred1)\n",
        "compare_results(Y_train, Y_train_pred1)\n",
        "compare_results(Y, Y_pred1)"
      ],
      "metadata": {
        "id": "-gfjC9sRQ9qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f4dfeb-2f34-4051-8a61-04bf9aa23af7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 0.07\n",
            "Mean absolute error: 0.16\n",
            "Mean absolute percentage error: 0.02\n",
            "                0           1           2\n",
            "count  120.000000  120.000000  120.000000\n",
            "mean    -0.001474    0.000088    0.048261\n",
            "std      0.088959    0.132599    0.435323\n",
            "min     -0.291102   -0.361600   -1.130479\n",
            "25%     -0.053582   -0.075739   -0.116390\n",
            "50%     -0.003766   -0.007725    0.040149\n",
            "75%      0.056599    0.085539    0.269438\n",
            "max      0.203584    0.312370    2.036858\n",
            "Mean squared error: 0.03\n",
            "Mean absolute error: 0.12\n",
            "Mean absolute percentage error: 0.01\n",
            "                0           1           2\n",
            "count  280.000000  280.000000  280.000000\n",
            "mean    -0.000083    0.000171    0.000033\n",
            "std      0.080954    0.130827    0.268307\n",
            "min     -0.242785   -0.445312   -0.932092\n",
            "25%     -0.057644   -0.085198   -0.142878\n",
            "50%      0.002692   -0.006517    0.005881\n",
            "75%      0.057483    0.085871    0.156870\n",
            "max      0.184835    0.310032    0.912101\n",
            "Mean squared error: 0.04\n",
            "Mean absolute error: 0.13\n",
            "Mean absolute percentage error: 0.01\n",
            "                0           1           2\n",
            "count  400.000000  400.000000  400.000000\n",
            "mean    -0.000500    0.000146    0.014501\n",
            "std      0.083325    0.131195    0.327638\n",
            "min     -0.291102   -0.445312   -1.130479\n",
            "25%     -0.056658   -0.084237   -0.136552\n",
            "50%      0.001673   -0.006517    0.015876\n",
            "75%      0.057058    0.085871    0.176906\n",
            "max      0.203584    0.312370    2.036858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we want to submit new data we must remember to explicitly scale\n",
        "Y345 = mlp.predict(scaler.transform(np.array([3, 4]).reshape(1,-1)))\n",
        "nprint(Y345,'Y345')"
      ],
      "metadata": {
        "id": "v-vmoxt65dMk",
        "outputId": "a75e33b9-06ef-4d54-aedc-994bab9e53f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y345 (1, 3) float64\n",
            "[[ 5.0418 12.0578  5.9985]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Pipeline"
      ],
      "metadata": {
        "id": "hyt4Q6xIP0pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('MLP', MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
        "          hidden_layer_sizes=(20,20),\n",
        "          activation='relu',\n",
        "          max_iter=10000,\n",
        "          random_state=1,\n",
        "          verbose=True))\n",
        "    ])\n",
        "pipe.fit(X_train, Y_train)\n",
        "Y_pred2 = pipe.predict(X)\n",
        "Y_test_pred2 = pipe.predict(X_test)\n",
        "Y_train_pred2 = pipe.predict(X_train)\n",
        "\n",
        "fprint(np.hstack([Y, Y_pred2]),'Y:Y_pred2')\n",
        "\n",
        "print(f\"pipe.score = {100*pipe.score(X_test, Y_test):.4f}%\")\n",
        "compare_results(Y_test, Y_test_pred2)\n",
        "compare_results(Y_train, Y_train_pred2)\n",
        "compare_results(Y, Y_pred2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BbUPp8oFR9J",
        "outputId": "522374ec-97dd-4a58-917f-3b434116fcbc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipe.score = 99.9809%\n",
            "Mean squared error: 0.07\n",
            "Mean absolute error: 0.16\n",
            "Mean absolute percentage error: 0.02\n",
            "                0           1           2\n",
            "count  120.000000  120.000000  120.000000\n",
            "mean    -0.001474    0.000088    0.048261\n",
            "std      0.088959    0.132599    0.435323\n",
            "min     -0.291102   -0.361600   -1.130479\n",
            "25%     -0.053582   -0.075739   -0.116390\n",
            "50%     -0.003766   -0.007725    0.040149\n",
            "75%      0.056599    0.085539    0.269438\n",
            "max      0.203584    0.312370    2.036858\n",
            "Mean squared error: 0.03\n",
            "Mean absolute error: 0.12\n",
            "Mean absolute percentage error: 0.01\n",
            "                0           1           2\n",
            "count  280.000000  280.000000  280.000000\n",
            "mean    -0.000083    0.000171    0.000033\n",
            "std      0.080954    0.130827    0.268307\n",
            "min     -0.242785   -0.445312   -0.932092\n",
            "25%     -0.057644   -0.085198   -0.142878\n",
            "50%      0.002692   -0.006517    0.005881\n",
            "75%      0.057483    0.085871    0.156870\n",
            "max      0.184835    0.310032    0.912101\n",
            "Mean squared error: 0.04\n",
            "Mean absolute error: 0.13\n",
            "Mean absolute percentage error: 0.01\n",
            "                0           1           2\n",
            "count  400.000000  400.000000  400.000000\n",
            "mean    -0.000500    0.000146    0.014501\n",
            "std      0.083325    0.131195    0.327638\n",
            "min     -0.291102   -0.445312   -1.130479\n",
            "25%     -0.056658   -0.084237   -0.136552\n",
            "50%      0.001673   -0.006517    0.015876\n",
            "75%      0.057058    0.085871    0.176906\n",
            "max      0.203584    0.312370    2.036858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show how easy it is to use the pipeline and scaling\n",
        "Y345 = pipe.predict(np.array([3, 4]).reshape(1,-1))\n",
        "nprint(Y345,'Y345')"
      ],
      "metadata": {
        "id": "ZKJkbNTC5HBU",
        "outputId": "d601b358-f23f-4e6a-ea69-28b8e10fd051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y345 (1, 3) float64\n",
            "[[ 5.0418 12.0578  5.9985]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iY1X032p5JJX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}