{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nedlecky/CSC485B/blob/main/CSC485_121_PythagorasMLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSC 485B Spring 2023: CSC485_120_Pythagoras using MLP\n",
        "## Can we figure out the Pythagorean Theorem with an MLP?\n",
        "### Input the length of the two sides, ML computes hypotenuse, perimeter, and area\n",
        "* SUNY Plattsburgh, Spring 2023\n",
        "* Dr. Ned Lecky\n",
        "* nleck001@plattsburgh.edu\n",
        "* ned@lecky.com"
      ],
      "metadata": {
        "id": "QBwjvn9X7lgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Support Functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This makes us reproducible (and we can adjust fixed_seed to get different results)\n",
        "fixed_seed = 1\n",
        "np.random.seed(fixed_seed)\n",
        "\n",
        "# Return n random floats between lo and hi as 1-column NumPy matrix\n",
        "def rand_nlohi(n=1, lo=0, hi=1):\n",
        "  # This is just a uniform distribution from lo to hi... we can adjust if appropriate in the future\n",
        "  return (np.random.rand(n) * (hi - lo) + lo).reshape(-1,1)\n",
        "\n",
        "def nprint(m, name=''):\n",
        "  print(f\"{name} {m.shape} {m.dtype}\")\n",
        "  print(m)\n",
        "\n"
      ],
      "metadata": {
        "id": "0B_bKL2AjY7z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nedp4wU8pITb"
      },
      "outputs": [],
      "source": [
        "# Test input data for right triangles\n",
        "# Reminder: We tell you the length of the two sides, you compute length of hypotenuse, perimeter, and area\n",
        "# x = [side1, side2]\n",
        "# y = [hypotenuse, perimeter, area]\n",
        "N = 40\n",
        "side1 = rand_nlohi(N,1,100)\n",
        "side2 = rand_nlohi(N,1,100)\n",
        "X = np.hstack([side1, side2])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's compute the expected results\n",
        "# Reminder: We tell you the length of the two sides, you compute length of hypotenuse, perimeter, and area\n",
        "# x = [side1, side2]\n",
        "# y = [hypotenuse, perimeter, area]\n",
        "hypotenuse = np.sqrt(np.square(side1) + np.square(side2))\n",
        "perimeter = side1 + side2 + hypotenuse\n",
        "area = (side1 * side2) / 2.\n",
        "Y = np.hstack([hypotenuse, perimeter, area])\n"
      ],
      "metadata": {
        "id": "w0drnB6qkR9v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Networks like inputs to be scaled down to +/- 1\n",
        "from sklearn import preprocessing\n",
        "\n",
        "std_scaler = preprocessing.StandardScaler()\n",
        "std_scaler.fit(X)\n",
        "X_std = std_scaler.transform(X)\n",
        "#print(np.hstack([X,X_std]))"
      ],
      "metadata": {
        "id": "a6lnQycVIwYR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# This is a train/test function that lets us pass in hyperparameters so we can trial\n",
        "def try_MLP(X, Y, hidden_layer_sizes=(5,2),\n",
        "            activation='relu', max_iter=200, title='Predictions'):\n",
        "  global regr # leaving it global so we can use the (last) one in additional tests\n",
        "  regr = MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
        "                     hidden_layer_sizes=hidden_layer_sizes,\n",
        "                     activation=activation,\n",
        "                     max_iter=max_iter,\n",
        "                     random_state=1)\n",
        "  regr.fit(X, Y)\n",
        "\n",
        "  # Add the reshape since decision tree outputs 18,1 otherwise\n",
        "  Y_pred = regr.predict(X)\n",
        "  print(f\"Mean squared error: {mean_squared_error(Y, Y_pred):.2f}\")\n",
        "  print(f\"Mean absolute error: {mean_absolute_error(Y, Y_pred):.2f}\")\n",
        "  print(f\"Mean absolute percentage error: {mean_absolute_percentage_error(Y, Y_pred):.2f}\")\n",
        "\n",
        "  # Put error in pandas so we can use .describe()\n",
        "  #e1 = pd.DataFrame(Y_pred[:0] - Y[:0], columns=['deltaHyp'])\n",
        "  #print(e1.describe())\n",
        "\n",
        "# What's ReLU (Rectified Linear Unit)\n",
        "# https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\n",
        "\n",
        "# Hyperparameter experiments\n",
        "hyperparameter_trials = [\n",
        "    [(7,4),'relu',200],\n",
        "    [(8,5),'relu',200],\n",
        "    [(12,6),'relu',200],\n",
        "    [(20,20),'relu',200],\n",
        "    [(40,40),'identity',200],\n",
        "    [(40,40),'logistic',1000],\n",
        "    [(40,40),'relu',1000],\n",
        "    [(40,40),'relu',10000],\n",
        "]\n",
        "\n",
        "for hyperparam in hyperparameter_trials:\n",
        "  print(f\"Trying: {hyperparam}\")\n",
        "  try_MLP(X_std, Y, hidden_layer_sizes=hyperparam[0], activation=hyperparam[1], max_iter=hyperparam[2], title=f\"Predictions {hyperparam}\")\n"
      ],
      "metadata": {
        "id": "YDCaPOeifAYp",
        "outputId": "536f21e2-54ae-47b3-e893-e93ab10a3fea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying: [(7, 4), 'relu', 200]\n",
            "Mean squared error: 640.29\n",
            "Mean absolute error: 18.96\n",
            "Mean absolute percentage error: 0.18\n",
            "Trying: [(8, 5), 'relu', 200]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 1544.96\n",
            "Mean absolute error: 20.75\n",
            "Mean absolute percentage error: 0.13\n",
            "Trying: [(12, 6), 'relu', 200]\n",
            "Mean squared error: 570.92\n",
            "Mean absolute error: 16.40\n",
            "Mean absolute percentage error: 0.11\n",
            "Trying: [(20, 20), 'relu', 200]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 44.99\n",
            "Mean absolute error: 4.06\n",
            "Mean absolute percentage error: 0.02\n",
            "Trying: [(40, 40), 'identity', 200]\n",
            "Mean squared error: 43691.90\n",
            "Mean absolute error: 99.09\n",
            "Mean absolute percentage error: 0.60\n",
            "Trying: [(40, 40), 'logistic', 1000]\n",
            "Mean squared error: 36450.11\n",
            "Mean absolute error: 97.26\n",
            "Mean absolute percentage error: 0.67\n",
            "Trying: [(40, 40), 'relu', 1000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 0.64\n",
            "Mean absolute error: 0.39\n",
            "Mean absolute percentage error: 0.00\n",
            "Trying: [(40, 40), 'relu', 10000]\n",
            "Mean squared error: 0.49\n",
            "Mean absolute error: 0.35\n",
            "Mean absolute percentage error: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# That looks pretty good... let's try some examples not from the dataset\n",
        "# Here's a 3,4 triangle- expect hypotenuse = 5, perimeter = 3 + 4 + 5 = 12, area = 6\n",
        "X_345 = np.array([3,4]).reshape(1,-1)\n",
        "nprint(X_345,'X_345')\n",
        "\n",
        "# Don't forget to scale the inputs the same way we did for training!\n",
        "Y_pred = regr.predict(std_scaler.transform(X_345))\n",
        "nprint(Y_pred,'Y_pred 345')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipm2x89mM1bw",
        "outputId": "f2a7655c-5fa0-42c7-f7b3-584cb611da3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_345 (1, 2) int64\n",
            "[[3 4]]\n",
            "Y_pred 345 (1, 3) float64\n",
            "[[ 15.13140054  30.73078325 -12.54381308]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not thrilled... how about for large triangles??\n",
        "X_304050 = X_345*10;\n",
        "nprint(X_304050,'X_304050')\n",
        "\n",
        "# Don't forget to scale the inputs the same way we did for training!\n",
        "Y_pred = regr.predict(std_scaler.transform(X_304050))\n",
        "nprint(Y_pred,'Y_pred 304050')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1ExQlk25OoS",
        "outputId": "2ca99fb8-96b7-4fc1-8298-90036c9f4e3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_304050 (1, 2) int64\n",
            "[[30 40]]\n",
            "Y_pred 304050 (1, 3) float64\n",
            "[[ 48.75359696 120.17843703 668.69497035]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OK... how about much larger data??\n",
        "def make_dataset(n = 40):\n",
        "  global N\n",
        "  N = n\n",
        "  # Initially... not so great on small or extra large\n",
        "  side1 = rand_nlohi(N,1,100)\n",
        "  side2 = rand_nlohi(N,1,100)\n",
        "  #side1 = rand_nlohi(N,10,500)\n",
        "  #side2 = rand_nlohi(N,10,500)\n",
        "  X = np.hstack([side1, side2])\n",
        "\n",
        "  hypotenuse = np.sqrt(np.square(side1) + np.square(side2))\n",
        "  perimeter = side1 + side2 + hypotenuse\n",
        "  area = (side1 * side2) / 2.\n",
        "  Y = np.hstack([hypotenuse, perimeter, area])\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "\n",
        "# Initially... maybe need even more?\n",
        "#X, Y = make_dataset(100)\n",
        "X, Y = make_dataset(300)\n",
        "\n",
        "std_scaler = preprocessing.StandardScaler()\n",
        "std_scaler.fit(X)\n",
        "X_std = std_scaler.transform(X)\n",
        "\n",
        "# Hyperparameter experiments\n",
        "hyperparameter_trials = [\n",
        "#    [(20,20),'relu',5000],\n",
        "#    [(20,50,20,10),'relu',10000],\n",
        "    [(100,50,20,10),'relu',10000],\n",
        "]\n",
        "\n",
        "for hyperparam in hyperparameter_trials:\n",
        "  print(f\"Trying: {hyperparam}\")\n",
        "  try_MLP(X_std, Y, hidden_layer_sizes=hyperparam[0], activation=hyperparam[1], max_iter=hyperparam[2], title=f\"Predictions {hyperparam}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAboaDLRNWLG",
        "outputId": "aac67f5a-c7eb-4643-f496-aaba6dff373d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying: [(100, 50, 20, 10), 'relu', 10000]\n",
            "Mean squared error: 0.28\n",
            "Mean absolute error: 0.37\n",
            "Mean absolute percentage error: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = regr.predict(std_scaler.transform(X_345))\n",
        "nprint(Y_pred,'Y_pred 345')\n",
        "Y_pred = regr.predict(std_scaler.transform(X_304050))\n",
        "nprint(Y_pred,'Y_pred 304050')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjzsErisPeLY",
        "outputId": "f535855d-d2d0-4039-fe00-ab1ad1c5ef53"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_pred 345 (1, 3) float64\n",
            "[[12.33358863 30.85636108 15.26690451]]\n",
            "Y_pred 304050 (1, 3) float64\n",
            "[[ 50.85636982 119.93016005 593.71977319]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And how is larger still?\n",
        "X_300400500 = X_345*100;\n",
        "nprint(X_300400500,'X_300400500')\n",
        "\n",
        "# Don't forget to scale the inputs the same way we did for training!\n",
        "Y_pred = regr.predict(std_scaler.transform(X_300400500))\n",
        "nprint(Y_pred,'Y_pred 300400500')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoGnAYgBRcgk",
        "outputId": "1abe279b-261e-4351-c879-017c81c7ea90"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_300400500 (1, 2) int64\n",
            "[[300 400]]\n",
            "Y_pred 300400500 (1, 3) float64\n",
            "[[  588.05337713  1427.211005   27686.44731321]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Doesn't this feel like spinning in darkness?????"
      ],
      "metadata": {
        "id": "nw52RbWbSndA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dA0ALdVZdxyu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}